{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25b9387",
   "metadata": {},
   "source": [
    "## Financial Sentiment Analysis Project\n",
    "# Preprozessing \n",
    "- Loading and exploring the data\n",
    "- Preprocessing\n",
    "- Adding flags for multiple tickers in one tweet\n",
    "- Merging and saving final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73b6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b2441",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7de1376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "sentiment_labeled_data: (5791, 2)\n",
      "stock_tweets: (80793, 4)\n",
      "stock_prices: (6300, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "sentiment_labeled_data = pd.read_csv('data/raw/stock_data.csv')\n",
    "stock_tweets = pd.read_csv('data/raw/stock_tweets_d1.csv')\n",
    "stock_prices = pd.read_csv('data/raw/stock_yfinance_data_d1.csv')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"sentiment_labeled_data: {sentiment_labeled_data.shape}\")\n",
    "print(f\"stock_tweets: {stock_tweets.shape}\")\n",
    "print(f\"stock_prices: {stock_prices.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f14838",
   "metadata": {},
   "source": [
    "## 2. Explore the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4faae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n",
      "                                                Text  Sentiment\n",
      "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
      "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
      "2  user I'd be afraid to short AMZN - they are lo...          1\n",
      "3                                  MNTA Over 12.00            1\n",
      "4                                   OI  Over 21.37            1\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5791 entries, 0 to 5790\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       5791 non-null   object\n",
      " 1   Sentiment  5791 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.6+ KB\n",
      "None\n",
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      " 1    3685\n",
      "-1    2106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "Text         0\n",
      "Sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore sentiment_labeled_data (labeled sentiment data)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(sentiment_labeled_data.head())\n",
    "print(\"\\nInfo:\")\n",
    "print(sentiment_labeled_data.info())\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(sentiment_labeled_data['Sentiment'].value_counts())\n",
    "print(\"\\nMissing values:\")\n",
    "print(sentiment_labeled_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaec6b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n",
      "                        Date  \\\n",
      "0  2022-09-29 23:41:16+00:00   \n",
      "1  2022-09-29 23:24:43+00:00   \n",
      "2  2022-09-29 23:18:08+00:00   \n",
      "3  2022-09-29 22:40:07+00:00   \n",
      "4  2022-09-29 22:27:05+00:00   \n",
      "\n",
      "                                               Tweet Stock Name Company Name  \n",
      "0  Mainstream media has done an amazing job at br...       TSLA  Tesla, Inc.  \n",
      "1  Tesla delivery estimates are at around 364k fr...       TSLA  Tesla, Inc.  \n",
      "2  3/ Even if I include 63.0M unvested RSUs as of...       TSLA  Tesla, Inc.  \n",
      "3  @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...       TSLA  Tesla, Inc.  \n",
      "4  @RealDanODowd @Tesla Stop trying to kill kids,...       TSLA  Tesla, Inc.  \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80793 entries, 0 to 80792\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Date          80793 non-null  object\n",
      " 1   Tweet         80793 non-null  object\n",
      " 2   Stock Name    80793 non-null  object\n",
      " 3   Company Name  80793 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "\n",
      "Unique stocks:\n",
      "Stock Name\n",
      "TSLA    37422\n",
      "TSM     11034\n",
      "AAPL     5056\n",
      "AMZN     4089\n",
      "MSFT     4089\n",
      "PG       4089\n",
      "NIO      3021\n",
      "META     2751\n",
      "AMD      2227\n",
      "NFLX     1727\n",
      "GOOG     1291\n",
      "PYPL      843\n",
      "DIS       635\n",
      "BA        399\n",
      "COST      393\n",
      "INTC      315\n",
      "KO        310\n",
      "CRM       233\n",
      "XPEV      225\n",
      "ENPH      216\n",
      "ZS        193\n",
      "VZ        123\n",
      "BX         50\n",
      "F          31\n",
      "NOC        31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "Date            0\n",
      "Tweet           0\n",
      "Stock Name      0\n",
      "Company Name    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore stock_tweets (tweets with stock info)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(stock_tweets.head())\n",
    "print(\"\\nInfo:\")\n",
    "print(stock_tweets.info())\n",
    "print(\"\\nUnique stocks:\")\n",
    "print(stock_tweets['Stock Name'].value_counts())\n",
    "print(\"\\nMissing values:\")\n",
    "print(stock_tweets.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74b5b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2021-09-30  260.333344  263.043335  258.333344  258.493347  258.493347   \n",
      "1  2021-10-01  259.466675  260.260010  254.529999  258.406677  258.406677   \n",
      "2  2021-10-04  265.500000  268.989990  258.706665  260.510010  260.510010   \n",
      "3  2021-10-05  261.600006  265.769989  258.066681  260.196655  260.196655   \n",
      "4  2021-10-06  258.733337  262.220001  257.739990  260.916656  260.916656   \n",
      "\n",
      "     Volume Stock Name  \n",
      "0  53868000       TSLA  \n",
      "1  51094200       TSLA  \n",
      "2  91449900       TSLA  \n",
      "3  55297800       TSLA  \n",
      "4  43898400       TSLA  \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6300 entries, 0 to 6299\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Date        6300 non-null   object \n",
      " 1   Open        6300 non-null   float64\n",
      " 2   High        6300 non-null   float64\n",
      " 3   Low         6300 non-null   float64\n",
      " 4   Close       6300 non-null   float64\n",
      " 5   Adj Close   6300 non-null   float64\n",
      " 6   Volume      6300 non-null   int64  \n",
      " 7   Stock Name  6300 non-null   object \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 393.9+ KB\n",
      "None\n",
      "\n",
      "Date range:\n",
      "From 2021-09-30 00:00:00 to 2022-09-29 00:00:00\n",
      "\n",
      "Unique stocks:\n",
      "Stock Name\n",
      "TSLA    252\n",
      "MSFT    252\n",
      "PG      252\n",
      "META    252\n",
      "AMZN    252\n",
      "GOOG    252\n",
      "AMD     252\n",
      "AAPL    252\n",
      "NFLX    252\n",
      "TSM     252\n",
      "KO      252\n",
      "F       252\n",
      "COST    252\n",
      "DIS     252\n",
      "VZ      252\n",
      "CRM     252\n",
      "INTC    252\n",
      "BA      252\n",
      "BX      252\n",
      "NOC     252\n",
      "PYPL    252\n",
      "ENPH    252\n",
      "NIO     252\n",
      "ZS      252\n",
      "XPEV    252\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "Date          0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "Close         0\n",
      "Adj Close     0\n",
      "Volume        0\n",
      "Stock Name    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore stock_prices (yfinance data)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(stock_prices.head())\n",
    "print(\"\\nInfo:\")\n",
    "print(stock_prices.info())\n",
    "print(\"\\nDate range:\")\n",
    "stock_prices['Date'] = pd.to_datetime(stock_prices['Date'])\n",
    "print(f\"From {stock_prices['Date'].min()} to {stock_prices['Date'].max()}\")\n",
    "print(\"\\nUnique stocks:\")\n",
    "print(stock_prices['Stock Name'].value_counts())\n",
    "print(\"\\nMissing values:\")\n",
    "print(stock_prices.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33830898",
   "metadata": {},
   "source": [
    "## 3. Clean and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad5b5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We dont want to clean the data too much sincce finbert is trained on finance specific tweets. \n",
    "# We only want to remove urls, user mentions, hashtags, and html entities. \n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess tweet text, preserves stock ticker symbols as ticker_XXX\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove user mentions and hashtags symbols (but keep the text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Remove HTML entities like &amp;\n",
    "    text = re.sub(r'&\\w+;', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9459f416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing clean_text function ===\n",
      "\n",
      "Test 1:\n",
      "Original: Tesla delivery estimates are at around 364k from the analysts. $tsla\n",
      "Cleaned:  Tesla delivery estimates are at around 364k from the analysts. $tsla\n",
      "\n",
      "Test 2:\n",
      "Original: $NIO just because I'm down money doesn't mean this is a bad investment. $AAPL $AMZN $TSLA $GOOGL $NIO\n",
      "Cleaned:  $NIO just because I'm down money doesn't mean this is a bad investment. $AAPL $AMZN $TSLA $GOOGL $NIO\n",
      "\n",
      "Test 3:\n",
      "Original: 3/ Even if I include 63.0M unvested RSUs as of 6/30, additional equity needed for the RSUs is 63.0M x $54.20 = $3.4B. $twtr $tsla\n",
      "Cleaned:  3/ Even if I include 63.0M unvested RSUs as of 6/30, additional equity needed for the RSUs is 63.0M x $54.20 = $3.4B. $twtr $tsla\n",
      "\n",
      "Test 4:\n",
      "Original: Mainstream media has done an amazing job at brainwashing people. @Tesla &amp; EVERYONE disagreed\n",
      "Cleaned:  Mainstream media has done an amazing job at brainwashing people. EVERYONE disagreed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the improved clean_text function\n",
    "test_tweets = [\n",
    "    \"Tesla delivery estimates are at around 364k from the analysts. $tsla\",  # lowercase ticker\n",
    "    \"$NIO just because I'm down money doesn't mean this is a bad investment. $AAPL $AMZN $TSLA $GOOGL $NIO\",  # multiple tickers\n",
    "    \"3/ Even if I include 63.0M unvested RSUs as of 6/30, additional equity needed for the RSUs is 63.0M x $54.20 = $3.4B. $twtr $tsla\",  # mixed case\n",
    "    \"Mainstream media has done an amazing job at brainwashing people. @Tesla &amp; EVERYONE disagreed\",  # HTML entity\n",
    "]\n",
    "\n",
    "print(\"=== Testing clean_text function ===\\n\")\n",
    "for i, tweet in enumerate(test_tweets, 1):\n",
    "    cleaned = clean_text(tweet)\n",
    "    print(f\"Test {i}:\")\n",
    "    print(f\"Original: {tweet}\")\n",
    "    print(f\"Cleaned:  {cleaned}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3f960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 5791\n",
      "Rows after cleaning: 5791\n",
      "\n",
      "Sample cleaned tweets:\n",
      "                                                Text  \\\n",
      "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...   \n",
      "1  user: AAP MOVIE. 55% return for the FEA/GEED i...   \n",
      "2  user I'd be afraid to short AMZN - they are lo...   \n",
      "3                                  MNTA Over 12.00     \n",
      "4                                   OI  Over 21.37     \n",
      "\n",
      "                                        cleaned_text  Sentiment  \n",
      "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1  \n",
      "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1  \n",
      "2  user I'd be afraid to short AMZN - they are lo...          1  \n",
      "3                                    MNTA Over 12.00          1  \n",
      "4                                      OI Over 21.37          1  \n"
     ]
    }
   ],
   "source": [
    "# Process sentiment_labeled_data (labeled sentiment tweets)\n",
    "sentiment_labeled_data_cleaned = sentiment_labeled_data.copy()\n",
    "\n",
    "# Clean the text\n",
    "sentiment_labeled_data_cleaned['cleaned_text'] = sentiment_labeled_data_cleaned['Text'].apply(clean_text)\n",
    "\n",
    "# Remove rows with empty cleaned text\n",
    "sentiment_labeled_data_cleaned = sentiment_labeled_data_cleaned[sentiment_labeled_data_cleaned['cleaned_text'].str.len() > 0]\n",
    "\n",
    "print(f\"Original rows: {len(sentiment_labeled_data)}\")\n",
    "print(f\"Rows after cleaning: {len(sentiment_labeled_data_cleaned)}\")\n",
    "print(f\"\\nSample cleaned tweets:\")\n",
    "print(sentiment_labeled_data_cleaned[['Text', 'cleaned_text', 'Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f0c562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 80793\n",
      "Rows after cleaning: 80793\n",
      "\n",
      "Sample cleaned tweets:\n",
      "                       Date  \\\n",
      "0 2022-09-29 23:41:16+00:00   \n",
      "1 2022-09-29 23:24:43+00:00   \n",
      "2 2022-09-29 23:18:08+00:00   \n",
      "3 2022-09-29 22:40:07+00:00   \n",
      "4 2022-09-29 22:27:05+00:00   \n",
      "\n",
      "                                       cleaned_tweet Stock Name  \n",
      "0  Mainstream media has done an amazing job at br...       TSLA  \n",
      "1  Tesla delivery estimates are at around 364k fr...       TSLA  \n",
      "2  3/ Even if I include 63.0M unvested RSUs as of...       TSLA  \n",
      "3  Hahaha why are you still trying to stop Tesla ...       TSLA  \n",
      "4  Stop trying to kill kids, you sad deranged old...       TSLA  \n"
     ]
    }
   ],
   "source": [
    "# Process stock_tweets\n",
    "stock_tweets_cleaned = stock_tweets.copy()\n",
    "\n",
    "# Convert date column to datetime\n",
    "stock_tweets_cleaned['Date'] = pd.to_datetime(stock_tweets_cleaned['Date'])\n",
    "\n",
    "# Clean the tweet text\n",
    "stock_tweets_cleaned['cleaned_tweet'] = stock_tweets_cleaned['Tweet'].apply(clean_text)\n",
    "\n",
    "# Remove rows with empty cleaned text\n",
    "stock_tweets_cleaned = stock_tweets_cleaned[stock_tweets_cleaned['cleaned_tweet'].str.len() > 0]\n",
    "\n",
    "# Extract date only (without time) for easier merging with stock prices\n",
    "stock_tweets_cleaned['date_only'] = stock_tweets_cleaned['Date'].dt.date\n",
    "\n",
    "\n",
    "print(f\"Original rows: {len(stock_tweets)}\")\n",
    "print(f\"Rows after cleaning: {len(stock_tweets_cleaned)}\")\n",
    "print(f\"\\nSample cleaned tweets:\")\n",
    "print(stock_tweets_cleaned[['Date', 'cleaned_tweet', 'Stock Name']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f196c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "valid_tickers = set(stock_prices['Stock Name'].unique())\n",
    "print(len(valid_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23666b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'AMD', 'AMZN', 'BA', 'BX', 'COST', 'CRM', 'DIS', 'ENPH', 'F', 'GOOG', 'INTC', 'KO', 'META', 'MSFT', 'NFLX', 'NIO', 'NOC', 'PG', 'PYPL', 'TSLA', 'TSM', 'VZ', 'XPEV', 'ZS']\n",
      "Original tweets: 80793\n",
      "Tweets with valid tickers: 58830\n",
      "  - Single stock: 42726\n",
      "  - Multiple stocks: 16104\n",
      "Removed (no valid tickers): 21963\n",
      "\n",
      "Sample results:\n",
      "                                        cleaned_tweet  \\\n",
      "1   Tesla delivery estimates are at around 364k fr...   \n",
      "2   3/ Even if I include 63.0M unvested RSUs as of...   \n",
      "7   $NIO just because I'm down money doesn't mean ...   \n",
      "8    50 likes for some $SPY $TSLA charts to study! ❤️   \n",
      "10  Tomorrow, Tesla, $TSLA, AI day 2 is ongoing. U...   \n",
      "12  $TSLAQ: Tesla’s dead in Europe! Everyone else ...   \n",
      "14  Tesla AI day in 24 hours. Are you ready? $TSLA...   \n",
      "15                Picked up some $TSLA shares at $269   \n",
      "16  2/ Even if loses the $TWTR trial (would more l...   \n",
      "17  Everyone should keep a long term perspective. ...   \n",
      "\n",
      "          mentioned_tickers      ticker_flag  \n",
      "1                    [TSLA]     single stock  \n",
      "2                    [TSLA]     single stock  \n",
      "7   [NIO, AAPL, AMZN, TSLA]  multiple stocks  \n",
      "8                    [TSLA]     single stock  \n",
      "10                   [TSLA]     single stock  \n",
      "12                   [TSLA]     single stock  \n",
      "14                   [TSLA]     single stock  \n",
      "15                   [TSLA]     single stock  \n",
      "16                   [TSLA]     single stock  \n",
      "17                   [TSLA]     single stock  \n"
     ]
    }
   ],
   "source": [
    "def select_valid_tweets(stock_tweets_cleaned, valid_tickers):\n",
    "    \"\"\"\n",
    "    Expects a dataset of tweets with potentialstock tickers turned into ticker_XXX. \n",
    "    Goes trough the dataset, returns only the tweets containing valid tickers. And ads a \"single stock\" or \"multiple stocks\" column to the datset.\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = stock_tweets_cleaned.copy()\n",
    "\n",
    "    def get_valid_tickers(cleaned_text):\n",
    "        if pd.isna(cleaned_text):\n",
    "            return []\n",
    "        # Extract ticker_xxx patterns and check if xxx is in valid_tickers\n",
    "        mentioned = re.findall(r'\\$([A-Za-z]{1,5})\\b', cleaned_text)  \n",
    "        valid_mentioned = [t.upper() for t in mentioned if t.upper() in valid_tickers]\n",
    "        return list(set(valid_mentioned))  # Return unique\n",
    "\n",
    "\n",
    "    # Add mentioned_tickers column\n",
    "    df_copy['mentioned_tickers'] = df_copy['cleaned_tweet'].apply(get_valid_tickers)\n",
    "    \n",
    "    # Add number of tickers mentioned\n",
    "    df_copy['num_tickers'] = df_copy['mentioned_tickers'].apply(len)\n",
    "    \n",
    "    # Add single/multiple stock flag\n",
    "    df_copy['ticker_flag'] = df_copy['num_tickers'].apply(\n",
    "        lambda x: 'single stock' if x == 1 else ('multiple stocks' if x > 1 else 'no valid ticker')\n",
    "    )\n",
    "    \n",
    "    # Filter: keep only tweets with at least one valid ticker\n",
    "    df_filtered = df_copy[df_copy['num_tickers'] > 0].copy()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Original tweets: {len(stock_tweets_cleaned)}\")\n",
    "    print(f\"Tweets with valid tickers: {len(df_filtered)}\")\n",
    "    print(f\"  - Single stock: {(df_filtered['ticker_flag'] == 'single stock').sum()}\")\n",
    "    print(f\"  - Multiple stocks: {(df_filtered['ticker_flag'] == 'multiple stocks').sum()}\")\n",
    "    print(f\"Removed (no valid tickers): {len(stock_tweets_cleaned) - len(df_filtered)}\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "#\n",
    "#Valid tickers\n",
    "valid_tickers = sorted(set(stock_prices['Stock Name'].unique()))\n",
    "print(valid_tickers)\n",
    "# Filter our data\n",
    "stock_tweets_filtered = select_valid_tweets(stock_tweets_cleaned, valid_tickers)\n",
    "\n",
    "# Checkup\n",
    "print(\"\\nSample results:\")\n",
    "print(stock_tweets_filtered[['cleaned_tweet', 'mentioned_tickers', 'ticker_flag']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a1d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 6300\n",
      "Rows after processing: 6275\n",
      "\n",
      "Sample processed data:\n",
      "        Date        Open        High         Low       Close   Adj Close  \\\n",
      "1 2021-10-01  259.466675  260.260010  254.529999  258.406677  258.406677   \n",
      "2 2021-10-04  265.500000  268.989990  258.706665  260.510010  260.510010   \n",
      "3 2021-10-05  261.600006  265.769989  258.066681  260.196655  260.196655   \n",
      "4 2021-10-06  258.733337  262.220001  257.739990  260.916656  260.916656   \n",
      "5 2021-10-07  261.820007  268.333344  261.126678  264.536682  264.536682   \n",
      "\n",
      "     Volume Stock Name  daily_return  price_range   date_only  \n",
      "1  51094200       TSLA     -0.000335     5.730011  2021-10-01  \n",
      "2  91449900       TSLA      0.008140    10.283325  2021-10-04  \n",
      "3  55297800       TSLA     -0.001203     7.703308  2021-10-05  \n",
      "4  43898400       TSLA      0.002767     4.480011  2021-10-06  \n",
      "5  57587400       TSLA      0.013874     7.206665  2021-10-07  \n"
     ]
    }
   ],
   "source": [
    "# Process stock_prices\n",
    "stock_prices_cleaned = stock_prices.copy()\n",
    "\n",
    "# Date is already converted to datetime in previous cell\n",
    "# Calculate additional features\n",
    "stock_prices_cleaned['daily_return'] = stock_prices_cleaned.groupby('Stock Name')['Close'].pct_change()\n",
    "stock_prices_cleaned['price_range'] = stock_prices_cleaned['High'] - stock_prices_cleaned['Low']\n",
    "stock_prices_cleaned['date_only'] = stock_prices_cleaned['Date'].dt.date\n",
    "\n",
    "# Handle any missing values\n",
    "stock_prices_cleaned = stock_prices_cleaned.dropna()\n",
    "\n",
    "print(f\"Original rows: {len(stock_prices)}\")\n",
    "print(f\"Rows after processing: {len(stock_prices_cleaned)}\")\n",
    "print(f\"\\nSample processed data:\")\n",
    "print(stock_prices_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e1ac8",
   "metadata": {},
   "source": [
    "## 4. Merge Datasets (Filtered Tweets + Stock Prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd3df13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded tweets: 97663\n",
      "After merge with prices: 74846\n"
     ]
    }
   ],
   "source": [
    "# Explode so each mentioned ticker gets its own row\n",
    "tweets_exploded = stock_tweets_filtered.explode('mentioned_tickers')\n",
    "\n",
    "# Rename for merging\n",
    "tweets_exploded = tweets_exploded.rename(columns={'mentioned_tickers': 'Ticker'})\n",
    "\n",
    "# Merge with stock prices\n",
    "merged_data = tweets_exploded.merge(\n",
    "    stock_prices_cleaned,\n",
    "    on=['Stock Name', 'date_only'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Exploded tweets: {len(tweets_exploded)}\")\n",
    "print(f\"After merge with prices: {len(merged_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa133a",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a91ff2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets to the processed folder\n",
    "sentiment_labeled_data_cleaned.to_csv('data/processed/labeled_sentiment_tweets.csv', index=False)\n",
    "stock_tweets_cleaned.to_csv('data/processed/cleaned_stock_tweets.csv', index=False)\n",
    "stock_prices_cleaned.to_csv('data/processed/stock_prices_features.csv', index=False)\n",
    "merged_data.to_csv('data/processed/filtered_tweets_with_stock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ada39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
